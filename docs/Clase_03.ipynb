{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/bcataldo3/plantilla_curso_python/blob/main/docs/Clase_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# MACHINE LEARNING NO SUPERVISADO\n",
    "## Modelos de Conglomerados: K - Medias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición\n",
    "\n",
    "La agrupación K-means es un enfoque simple y elegante para dividir un conjunto de datos en K grupos distintos y no superpuestos. Para llevar a cabo la agrupación K-means, primero debemos especificar el número deseado de grupos K; luego, el algoritmo K-means asignará cada observación exactamente a uno de los K grupos.\n",
    "\n",
    "El procedimiento de agrupación K-means resulta de un problema matemático simple e intuitivo. Comenzamos definiendo algunas notaciones. Sea C1, ..., CK conjuntos que contienen los índices de las observaciones en cada cluster. Estos conjuntos satisfacen dos propiedades:\n",
    "\n",
    "* $C_1 \\cup C_2 \\cup ... \\cup C_k = \\{1, ..., n\\}$. En otras palabras, cada observación pertenece al menos a uno de los $K$ clusters.\n",
    "\n",
    "* Ck ∩ Ck′ = ∅ para todo k ≠ k′. En otras palabras, los clusters no se superponen: ninguna observación pertenece a más de un cluster.\n",
    "\n",
    "Por ejemplo, si la observación i-ésima está en el k-ésimo cluster, entonces i ∈ Ck. La idea detrás de la agrupación K-means es que una buena agrupación es aquella en la que la variación dentro del cluster es lo más pequeña posible. \n",
    "\n",
    "\n",
    "$\\sum_{n=1}^{N}n^{-s}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de Minimización\n",
    "\n",
    "La variación dentro del cluster para el cluster $C_k$ es una medida $W(C_k)$ de la cantidad por la cual las observaciones dentro de un cluster difieren entre sí. Por lo tanto, queremos resolver el problema:\n",
    "\n",
    "FORMULA DE MINIMIZACION\n",
    "\n",
    "En palabras, esta fórmula indica que deseamos dividir las observaciones en K clusters de manera que la variación total dentro de los clusters, sumada sobre todos los K clusters, sea lo más pequeña posible.\n",
    "\n",
    "Resolver la ecuación (10.9) parece ser una idea razonable, pero para llevarlo a cabo necesitamos definir la variación dentro del cluster.\n",
    "\n",
    "Existen muchas formas posibles de definir este concepto, pero la elección más común, de lejos, involucra la distancia euclidiana al cuadrado. Es decir, definimos\n",
    "\n",
    "FORMULA DE MINIMIZACION CON DISTANCIA EUCLIDIANA\n",
    "\n",
    "donde |Ck| denota el número de observaciones en el k-ésimo cluster. En otras palabras, la variación dentro del cluster para el k-ésimo cluster es la suma de todas las distancias euclidianas al cuadrado entre las observaciones en el k-ésimo cluster, dividida por el número total de observaciones en el k-ésimo cluster.\n",
    "\n",
    "Al combinar las ecuaciones (10.9) y (10.10), obtenemos el problema de optimización que define la agrupación K-means.\n",
    "\n",
    "FORMULA GLOBAL DE MINIMIZACION\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo\n",
    "\n",
    "Ahora, nos gustaría encontrar un algoritmo para resolver (10.11), es decir, un método para dividir las observaciones en K clusters de manera que se minimice el objetivo de (10.11). De hecho, este es un problema muy difícil de resolver de manera precisa, ya que hay casi Kn formas de dividir n observaciones en K clusters. Este número es enorme a menos que K y n sean muy pequeños. Afortunadamente, se puede demostrar que un algoritmo muy simple proporciona un óptimo local, es decir, una solución bastante buena, al problema de optimización de K-means (10.11). Este enfoque se detalla en el Algoritmo 10.1.\n",
    "\n",
    "\n",
    "El algoritmo de K-Medias consiste en seguir los siguientes pasos:\n",
    "\n",
    "1- Asignar aleatoriamente un número, del 1 al K, a cada una de las observaciones. Estos servirán como asignaciones iniciales de clusters para las observaciones.\n",
    "2- Iterar hasta que las asignaciones de clusters dejen de cambiar:\n",
    "* (a) Para cada uno de los K clusters, calcular el centroide del cluster. El centroide del k-ésimo cluster es el vector de las medias de las p características para las observaciones en el k-ésimo cluster.\n",
    "* (b) Asignar cada observación al cluster cuyo centroide esté más cerca (donde \"más cerca\" se define utilizando la distancia euclidiana).\n",
    "\n",
    "El Algoritmo 10.1 garantiza que disminuirá el valor del objetivo (10.11) en cada paso. En el Paso 2(a), las medias de los clusters para cada característica son las constantes que minimizan la suma de las desviaciones al cuadrado, y en el Paso 2(b), reasignar las observaciones solo puede mejorar (10.12). Esto significa que a medida que se ejecuta el algoritmo, la agrupación obtenida continuará mejorando hasta que el resultado ya no cambie; el objetivo de (10.11) nunca aumentará. Cuando el resultado ya no cambie, se habrá alcanzado un óptimo local. La agrupación K-means recibe su nombre debido a que en el Paso 2(a), los centroides de los clusters se calculan como la media de las observaciones asignadas a cada cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caso de Estudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url='https://drive.google.com/file/d/1LG6hb0duLtnSiFhT9JWFNuo8qDxHV08W/view?usp=drive_link'\n",
    "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
    "\n",
    "df = pd.read_csv(url, sep=\",\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones\n",
    "\n",
    "Debido a que el algoritmo K-means encuentra un óptimo local en lugar de uno global, los resultados obtenidos dependerán de la asignación de clusters iniciales (aleatoria) de cada observación en el Paso 1 del Algoritmo 10.1. Por esta razón, es importante ejecutar el algoritmo varias veces desde diferentes configuraciones iniciales aleatorias. Luego, se selecciona la mejor solución, es decir, aquella para la cual el objetivo (10.11) es el más pequeño. La Figura 10.7 muestra los óptimos locales obtenidos al ejecutar la agrupación K-means seis veces utilizando seis asignaciones iniciales de clusters diferentes, utilizando los datos de ejemplo de la Figura 10.5. En este caso, la mejor agrupación es la que tiene un valor objetivo de 235.8.\n",
    "\n",
    "Como hemos visto, para realizar la agrupación K-means, debemos decidir cuántos clusters esperamos en los datos. El problema de seleccionar K está lejos de ser simple. Este problema, junto con otras consideraciones prácticas que surgen al realizar la agrupación K-means, se aborda en la Sección 10.3.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
