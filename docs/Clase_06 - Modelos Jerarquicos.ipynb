{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING NO SUPERVISADO\n",
    "## Modelos de Conglomerados: Conglomerados Jerárquicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición\n",
    "\n",
    "\n",
    "Los resultados de aplicar algoritmos de agrupación K-means o K-medoids dependen de la elección del número de clusters a buscar y de una asignación de configuración inicial. En contraste, los métodos de agrupación jerárquica no requieren tales especificaciones. En cambio, requieren que el usuario especifique una medida de disimilitud entre grupos (disjuntos) de observaciones, basada en las disimilitudes pareja a pareja entre las observaciones en los dos grupos.\n",
    "\n",
    "Como su nombre sugiere, estos métodos producen representaciones jerárquicas en las que los clusters en cada nivel de la jerarquía se crean fusionando clusters en el nivel inferior siguiente. En el nivel más bajo, cada cluster contiene una sola observación. En el nivel más alto, hay solo un cluster que contiene todos los datos.\n",
    "\n",
    "Las estrategias para la agrupación jerárquica se dividen en dos paradigmas básicos: aglomerativo (de abajo hacia arriba) y divisivo (de arriba hacia abajo).\n",
    "\n",
    "Las estrategias aglomerativas comienzan desde abajo y en cada nivel fusionan de manera recursiva un par seleccionado de clusters en un solo cluster. Esto produce una agrupación en el nivel superior con un cluster menos. El par elegido para la fusión consta de los dos grupos con la menor disimilitud intergrupal.\n",
    "\n",
    "Los métodos divisivos comienzan desde arriba y en cada nivel dividen de manera recursiva uno de los clusters existentes en ese nivel en dos nuevos clusters. La división se elige para producir dos nuevos grupos con la mayor disimilitud entre grupos.\n",
    "\n",
    "Con ambos paradigmas, hay N - 1 niveles en la jerarquía, donde N es el número total de observaciones.\n",
    "\n",
    "Cada nivel de la jerarquía representa una agrupación particular de los datos en clusters disjuntos de observaciones. Toda la jerarquía representa una secuencia ordenada de tales agrupaciones. Depende del usuario decidir qué nivel (si alguno) representa en realidad una agrupación \"natural\" en el sentido de que las observaciones dentro de cada uno de sus grupos son lo suficientemente similares entre sí como para que difieran significativamente de las observaciones asignadas a diferentes grupos en ese nivel. El estadístico Gap mencionado anteriormente se puede utilizar para este propósito.\n",
    "\n",
    "La división/aglomeración binaria recursiva se puede representar mediante un árbol binario con raíz. Los nodos del árbol representan grupos. El nodo raíz representa el conjunto de datos completo. Los N nodos terminales representan cada uno de las observaciones individuales (clusters singleton). Cada nodo no terminal (\"padre\") tiene dos nodos hijas. Para la agrupación divisiva, las dos hijas representan los dos grupos resultantes de la división del padre; para la agrupación aglomerativa, las hijas representan los dos grupos que se fusionaron para formar el padre.\n",
    "\n",
    "### Metricas de Distancia\n",
    "\n",
    "Como se ha mencionado, se requiere de una métrica de distancia que define la disimilitud entre cada par de muestras. Ya hemos analizado muchos de ellos pero, en este\n",
    "En contexto, es útil comenzar a considerar la distancia genérica de Minkowski (parametrizada con $p$):\n",
    "\n",
    "$sdvsdvsd$\n",
    "\n",
    "Mencionamos dos casos particulares muy utilizados. Para $p=2$ tenemos la llamada distancia euclideana.\n",
    "\n",
    "$dsvsvsdvsd$\n",
    "\n",
    "Para $p=1$ se obtiene la distancia de Manhatan o distancia del taxista.\n",
    "\n",
    "$dsv vddssdds$\n",
    "\n",
    "Luego de elegir una distancia, pasamos a la creacion a la matriz de distancias $P$\n",
    "\n",
    "\n",
    "El siguiente paso es definir una estrategia de fusión, la cual, en este caso, se llama enlace. El objetivo de un método de enlace es encontrar los grupos que deben fusionarse en uno solo en cada nivel de la jerarquía. Por lo tanto, debe trabajar con conjuntos de muestras genéricas que representen los grupos. En este caso, supongamos que estamos analizando un par de grupos (Ca, Cb) y necesitamos encontrar qué índice, a o b, corresponde a la pareja que será fusionada.\n",
    "\n",
    "### Funciones de Enlace\n",
    "\n",
    "#### Enlace Simple\n",
    "El método de enlace simple selecciona la pareja que contiene el par más cercano de muestras (cada una de ellas perteneciente a un clúster diferente). Este proceso se muestra en el siguiente diagrama, donde se seleccionan C1 y C2 para fusionarse\n",
    "\n",
    "$skADLDLañ$\n",
    "\n",
    "(insertar figura)\n",
    "\n",
    "La principal desventaja de este método es la posibilidad de tener pequeños clústeres junto con otros muy grandes. Como veremos en la siguiente sección, el enlace único puede mantener aislados a los valores atípicos hasta que existan niveles de disimilitud muy altos. Para evitar o mitigar este problema, se pueden utilizar los métodos de promedio y Ward\n",
    "\n",
    "#### Enlace Completo\n",
    "El objetivo de este método de enlace es minimizar la distancia entre las muestras más alejadas que pertenecen a los clústeres fusionados. En el siguiente diagrama, se muestra un ejemplo de enlace completo, donde se han seleccionado C1 y C3. Su formula matemática es:\n",
    "\n",
    "$dvñsldvfsd$\n",
    "\n",
    "(insertar imagen)\n",
    "\n",
    "El algoritmo selecciona C1 y C3 para aumentar la cohesión interna. De hecho, es fácil entender que el enlace completo resulta en la maximización de la densidad del clúster, considerando todas las combinaciones posibles. En el ejemplo mostrado en el diagrama anterior, si el número deseado de clústeres es dos, fusionar C1 y C2 o C2 y C3 daría como resultado una configuración final con menos cohesión, lo cual suele ser un resultado no deseado\n",
    "\n",
    "\n",
    "#### Enlace Primedio\n",
    "\n",
    "$asvfvsdsdds$\n",
    "\n",
    "La idea es bastante similar al enlace completo, pero en este caso se tiene en cuenta el promedio de cada clúster y el objetivo es minimizar la distancia promedio entre clústeres, considerando todos los pares posibles (Ca, Cb). El siguiente diagrama muestra un ejemplo de enlace promedio\n",
    "\n",
    "(insertar imagen)\n",
    "\n",
    "El enlace promedio es particularmente útil en aplicaciones de bioinformática (que es el contexto principal en el que se ha definido el agrupamiento jerárquico). La explicación matemática de sus propiedades es compleja y te animo a consultar el artículo original (\"A Statistical Method for Evaluating Systematic Relationships\", Sokal R., Michener C., University of Kansas Science Bulletin, 38, 1958) para obtener más detalles.\n",
    "\n",
    "\n",
    "#### Enlace de Ward\n",
    "\n",
    "El último método que vamos a discutir se llama enlace de Ward (llamado así por su autor y originalmente propuesto en \"Hierarchical Grouping to Optimize an Objective Function\", Ward Jr J. H., Journal of the American Statistical Association. 58(301), 1963). Está basado en la distancia euclidiana y la definición formal es la siguiente:\n",
    "\n",
    "$fasflkasdmas$\n",
    "\n",
    "En cada nivel, se consideran todos los clústeres y se seleccionan dos de ellos con el objetivo de minimizar la suma de las distancias al cuadrado. El proceso en sí no difiere mucho del enlace promedio y es posible demostrar que el proceso de fusión conduce a una reducción en la varianza de los clústeres (es decir, aumenta su cohesión interna). Además, el enlace de Ward tiende a producir clústeres que contienen aproximadamente el mismo número de muestras (es decir, en comparación con el enlace único, el método de Ward evita la presencia de clústeres pequeños junto con otros muy grandes, como se discute en la siguiente sección). El enlace de Ward es una elección predeterminada popular, pero para tomar la decisión correcta en cada contexto específico, es necesario introducir el concepto de dendrograma.\n",
    "\n",
    "\n",
    "### Analisis de un Dendograma\n",
    "\n",
    "Todos los métodos aglomerativos y algunos métodos divisivos (cuando se ven de abajo hacia arriba) poseen una propiedad de monotonía. Es decir, la disimilitud entre los clusters fusionados aumenta monótonamente con el nivel de la fusión. Por lo tanto, el árbol binario se puede representar de manera que la altura de cada nodo sea proporcional al valor de la disimilitud intergrupal entre sus dos hijas. Los nodos terminales que representan observaciones individuales se representan todos a una altura de cero. Este tipo de representación gráfica se llama dendrograma.\n",
    "\n",
    "Un dendrograma proporciona una descripción completa y altamente interpretable de la agrupación jerárquica en un formato gráfico. Esta es una de las principales razones de la popularidad de los métodos de agrupación jerárquica.\n",
    "\n",
    "La idea es bastante sencilla: colocar las muestras en el eje x y el nivel de disimilitud en el eje y. Cada vez que dos clústeres se fusionan, el dendrograma muestra una conexión correspondiente al nivel de disimilitud en el que ocurrió la fusión. Por lo tanto, en un escenario aglomerativo, un dendrograma siempre comienza con todas las muestras consideradas como clústeres y se mueve hacia arriba (la dirección es puramente convencional) hasta que se define un solo clúster.\n",
    "\n",
    "Con fines didácticos, es preferible mostrar el dendrograma correspondiente a un conjunto de datos muy pequeño, X, pero todos los conceptos que vamos a discutir pueden aplicarse a cualquier situación. Sin embargo, con conjuntos de datos más grandes, a menudo será necesario aplicar algunas truncaciones para visualizar toda la estructura de una forma más compacta. Consideremos un conjunto de datos pequeño, X, compuesto por 12 muestras bidimensionales generadas por 4 distribuciones gaussianas con vectores medios en el rango (-1, 1) × (-1, 1):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs\n",
    "np.random.seed(1000)\n",
    "nb_samples = 12\n",
    "nb_centers = 4\n",
    "X, Y = make_blobs(n_samples=nb_samples, n_features=2, center_box=[-1, 1], centers=nb_centers, random_state=1000)\n",
    "\n",
    "# Show the dataset\n",
    "sns.set()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "for i, x in enumerate(X):\n",
    "    ax.scatter(x[0], x[1], s=120)\n",
    "    ax.annotate('%d' % i, xy=(x[0] + 0.05, x[1] + 0.05), fontsize=12)\n",
    "\n",
    "ax.set_xlabel(r'$x_0$', fontsize=14)\n",
    "ax.set_ylabel(r'$x_1$', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(insertamos imagen)\n",
    "\n",
    "Para generar un dendrograma (usando SciPy), primero necesitamos crear una matriz de enlace. En este caso, hemos elegido una métrica euclidiana con el enlace de Ward (pero, como es habitual, te animo a realizar el análisis con diferentes configuraciones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "dm = pdist(X, metric='euclidean')\n",
    "Z = linkage(dm, method='ward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
